SPARK1: spark-shell --packages mysql:mysql-connector-java:8.0.32
======

val df = spark.read.option("inferSchema","true").option("header","true").csv("hdfs://hdpmst:9000/data/diabetes.csv")

df.printSchema
root
 |-- Pregnancies: integer (nullable = true)
 |-- Glucose: integer (nullable = true)
 |-- BloodPressure: integer (nullable = true)
 |-- SkinThickness: integer (nullable = true)
 |-- Insulin: integer (nullable = true)
 |-- BMI: double (nullable = true)
 |-- DiabetesPedigreeFunction: double (nullable = true)
 |-- Age: integer (nullable = true)
 |-- Outcome: integer (nullable = true)
 
df.describe().show
+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+
|summary|       Pregnancies|          Glucose|     BloodPressure|     SkinThickness|           Insulin|               BMI|DiabetesPedigreeFunction|               Age|           Outcome|
+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+
|  count|               768|              768|               768|               768|               768|               768|                     768|               768|               768|
|   mean|3.8450520833333335|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.992578124999977|      0.4718763020833327|33.240885416666664|0.3489583333333333|
| stddev|  3.36957806269887|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803| 7.884160320375441|       0.331328595012775|11.760231540678689| 0.476951377242799|
|    min|                 0|                0|                 0|                 0|                 0|               0.0|                   0.078|                21|                 0|
|    max|                17|              199|               122|                99|               846|              67.1|                    2.42|                81|                 1|
+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+

import org.apache.spark.ml.feature.VectorAssembler
val va = new VectorAssembler().setOutputCol("features").setInputCols(df.columns.diff(Array("Outcome"))).setHandleInvalid("skip")

import org.apache.spark.ml.feature.StandardScaler
val stdScaler = new StandardScaler().
setWithStd(true).
setWithMean(true).
setInputCol("features").
setOutputCol("scaledFeatures")

import org.apache.spark.ml.classification.LogisticRegression
val lr = new LogisticRegression
lr.setRegParam(0.01).setMaxIter(100).setFitIntercept(true).setLabelCol("Outcome").setFeaturesCol("scaledFeatures")

val Array(trainingData, testData) = df.randomSplit(Array(0.7,0.3),11L)

trainingData.cache
testData.cache

import org.apache.spark.ml.Pipeline
val pipeline = new Pipeline().setStages(Array(va,stdScaler,lr))
val pipelinemodel = pipeline.fit(trainingData)

val pred = pipelinemodel.transform(testData)

pred.groupBy("prediction","Outcome").count.show
+----------+-------+-----+                                                      
|prediction|Outcome|count|
+----------+-------+-----+
|       1.0|      0|   13|
|       0.0|      0|  126|
|       0.0|      1|   37|
|       1.0|      1|   46|
+----------+-------+-----+

val predRDD = pred.select("prediction","Outcome").rdd.map( row => (row.getDouble(0),row.getInt(1).toDouble)).cache

import org.apache.spark.mllib.evaluation.MulticlassMetrics
val metrics = new MulticlassMetrics(predRDD)

metrics.accuracy
res25: Double = 0.7747747747747747

metrics.confusionMatrix
126.0  13.0
37.0   46.0

val pipelinemodel = pipeline.fit(df)
pipelinemodel.write.save("hdfs://hdpmst:9000/model/diabetes")
